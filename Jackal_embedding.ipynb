{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrTyoom/Project-Jackal/blob/ml-experiments/Jackal_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epp-pRQX8hFl"
      },
      "source": [
        "Импорт датасета"
      ],
      "id": "epp-pRQX8hFl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7292e5c4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ],
      "id": "7292e5c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a253fac"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r'first_command_new.csv')\n",
        "df2 = pd.read_csv(r'commands-w2v-version.csv')"
      ],
      "id": "3a253fac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98b880e5"
      },
      "outputs": [],
      "source": [
        "df[:3]\n",
        "df2[:3]"
      ],
      "id": "98b880e5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка и реализация word2vec"
      ],
      "metadata": {
        "id": "dij-z9rPX7IR"
      },
      "id": "dij-z9rPX7IR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGijKe4vIvic"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from gensim.models import Word2Vec"
      ],
      "id": "JGijKe4vIvic"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Uhq5rGiK5KR"
      },
      "outputs": [],
      "source": [
        "def generate_dictinoary_data(text):\n",
        "    word_to_index= dict()\n",
        "    index_to_word = dict()\n",
        "    corpus = []\n",
        "    count = 0\n",
        "    vocab_size = 0\n",
        "    \n",
        "    for row in text:\n",
        "        for word in row.split():\n",
        "            word = word.lower()\n",
        "            corpus.append(word)\n",
        "            if word_to_index.get(word) == None:\n",
        "                word_to_index.update ( {word : count})\n",
        "                index_to_word.update ( {count : word })\n",
        "                count  += 1\n",
        "    vocab_size = len(word_to_index)\n",
        "    length_of_corpus = len(corpus)\n",
        "    \n",
        "    return word_to_index,index_to_word,corpus,vocab_size,length_of_corpus\n"
      ],
      "id": "7Uhq5rGiK5KR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7vu22v0LSGQ"
      },
      "outputs": [],
      "source": [
        "generate_dictinoary_data(df['command'])"
      ],
      "id": "T7vu22v0LSGQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzrgZbC9IqoP"
      },
      "outputs": [],
      "source": [
        "# get the text data from the CSV file\n",
        "text_data = df['command'].tolist()\n",
        "\n",
        "# preprocess the text data\n",
        "preprocessed_text_data = []\n",
        "for text in text_data:\n",
        "    text = text.lower()\n",
        "    text = nltk.word_tokenize(text)\n",
        "    preprocessed_text_data.append(text)\n",
        "\n",
        "# train a Word2Vec model on the preprocessed text data\n",
        "model = Word2Vec(preprocessed_text_data, vector_size = 100, window=5, min_count=1, workers=4)"
      ],
      "id": "zzrgZbC9IqoP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybQsG-HpKIq6"
      },
      "outputs": [],
      "source": [
        "# use the Word2Vec model to get word embeddings\n",
        "embedding = model.wv['двигать']"
      ],
      "id": "ybQsG-HpKIq6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t06-d0DaItBR"
      },
      "outputs": [],
      "source": [
        "embedding"
      ],
      "id": "t06-d0DaItBR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получили словарь слов из всех команд и вектор для каждого слова в словаре"
      ],
      "metadata": {
        "id": "lWYlKH_FX_BM"
      },
      "id": "lWYlKH_FX_BM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем эмбеддинги с помощью другой модели  — SBERT"
      ],
      "metadata": {
        "id": "5ZSd5vRqYECA"
      },
      "id": "5ZSd5vRqYECA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFhAmpNo3sLj"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers"
      ],
      "id": "PFhAmpNo3sLj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JLNxNiSIs-6"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer as SBERT\n",
        "sbert1 = SBERT('sberbank-ai/sbert_large_nlu_ru')\n"
      ],
      "id": "0JLNxNiSIs-6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfjSGv8bIs6O"
      },
      "outputs": [],
      "source": [
        "EMBEDDING = sbert1.encode([s for s in df.command])\n",
        "EMBEDDING2 = sbert1.encode([s for s in df2.command])"
      ],
      "id": "sfjSGv8bIs6O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получили эмбеддинги из SBERT'a"
      ],
      "metadata": {
        "id": "OPJTE5m0YMzP"
      },
      "id": "OPJTE5m0YMzP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "  \\"
      ],
      "metadata": {
        "id": "9qCyZESyhfnY"
      },
      "id": "9qCyZESyhfnY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получим модель из эмбеддингов с помощью Сatboost'a"
      ],
      "metadata": {
        "id": "cnGLhyNEYRco"
      },
      "id": "cnGLhyNEYRco"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Zdvllm4SmO"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ],
      "id": "w7Zdvllm4SmO"
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost\n",
        "from catboost import * "
      ],
      "metadata": {
        "id": "XJcclEi4ZPPc"
      },
      "id": "XJcclEi4ZPPc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "8tZnk1YtJZAJ"
      },
      "id": "8tZnk1YtJZAJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['lables'] = le.fit_transform(df.intent)\n",
        "df2['lables'] = le.fit_transform(df2.intent)"
      ],
      "metadata": {
        "id": "-KuxMDyVJY42"
      },
      "id": "-KuxMDyVJY42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"lables\", axis=1)\n",
        "y = df[\"lables\"]\n",
        "\n",
        "X2 = df2.drop(\"lables\", axis=1)\n",
        "y2 = df2[\"lables\"]"
      ],
      "metadata": {
        "id": "SY_-FZsfZwUG"
      },
      "id": "SY_-FZsfZwUG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(EMBEDDING, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "sihirTUKJY9z"
      },
      "id": "sihirTUKJY9z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(EMBEDDING2, y2, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "WRoaQBWtlSQo"
      },
      "id": "WRoaQBWtlSQo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "model = CatBoostClassifier(iterations=100,\n",
        "                         learning_rate=0.2,\n",
        "                         depth=2, custom_loss=['AUC', 'Accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "         eval_set=(X_test, y_test),\n",
        "          verbose=50, plot=True\n",
        ")\n",
        "\n",
        "print(f\"Model is fitted: {str(model.is_fitted())}\")\n",
        "print(f\"Model params: {model.get_params()}\")\n"
      ],
      "metadata": {
        "id": "l23UbRXSTP7f"
      },
      "id": "l23UbRXSTP7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "model = CatBoostClassifier(iterations=100,\n",
        "                         learning_rate=0.2,\n",
        "                         depth=2, custom_loss=['AUC', 'Accuracy'])\n",
        "\n",
        "model.fit(X_train2, y_train2,\n",
        "         eval_set=(X_test2, y_test2),\n",
        "          verbose=50, plot=True\n",
        ")\n",
        "\n",
        "print(f\"Model is fitted: {str(model.is_fitted())}\")\n",
        "print(f\"Model params: {model.get_params()}\")\n"
      ],
      "metadata": {
        "id": "D7MNGtgLlmO_"
      },
      "id": "D7MNGtgLlmO_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Еще модели для сравнения"
      ],
      "metadata": {
        "id": "k1MAtsIQc3Au"
      },
      "id": "k1MAtsIQc3Au"
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = CatBoostClassifier(\n",
        "    learning_rate=0.7,\n",
        "    iterations=100,\n",
        "    random_seed=63,\n",
        "    train_dir='learning_rate_0.7'\n",
        ")\n",
        "\n",
        "model2 = CatBoostClassifier(\n",
        "    learning_rate=0.01,\n",
        "    iterations=100,\n",
        "    random_seed=63,\n",
        "    train_dir='learning_rate_0.01'\n",
        ")\n",
        "\n",
        "model1.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_test, y_test),\n",
        "    verbose=50\n",
        ")\n",
        "\n",
        "model2.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_test, y_test),\n",
        "    verbose=50\n",
        ")"
      ],
      "metadata": {
        "id": "-PWeJJ3xc4lh"
      },
      "id": "-PWeJJ3xc4lh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = CatBoostClassifier(\n",
        "    learning_rate=0.7,\n",
        "    iterations=100,\n",
        "    random_seed=63,\n",
        "    train_dir='learning_rate_0.7'\n",
        ")\n",
        "\n",
        "model4 = CatBoostClassifier(\n",
        "    learning_rate=0.01,\n",
        "    iterations=100,\n",
        "    random_seed=63,\n",
        "    train_dir='learning_rate_0.01'\n",
        ")\n",
        "\n",
        "model3.fit(\n",
        "    X_train2, y_train2,\n",
        "    eval_set=(X_test2, y_test2),\n",
        "    verbose=50\n",
        ")\n",
        "\n",
        "model4.fit(\n",
        "    X_train2, y_train2,\n",
        "    eval_set=(X_test2, y_test2),\n",
        "    verbose=50\n",
        ")"
      ],
      "metadata": {
        "id": "PfHdFWT8l5W6"
      },
      "id": "PfHdFWT8l5W6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь делаем predict"
      ],
      "metadata": {
        "id": "Tsip_efagXGp"
      },
      "id": "Tsip_efagXGp"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model2.predict(X_test, \n",
        "        prediction_type='Class', \n",
        "        ntree_start=0, \n",
        "        ntree_end=0, \n",
        "        thread_count=-1,\n",
        "        verbose=None)"
      ],
      "metadata": {
        "id": "RfOpT_BigY86"
      },
      "id": "RfOpT_BigY86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = model4.predict(X_test2, \n",
        "        prediction_type='Class', \n",
        "        ntree_start=0, \n",
        "        ntree_end=0, \n",
        "        thread_count=-1,\n",
        "        verbose=None)"
      ],
      "metadata": {
        "id": "tbzVNNuJmEP0"
      },
      "id": "tbzVNNuJmEP0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred) "
      ],
      "metadata": {
        "id": "_XiQIgp4feR4"
      },
      "id": "_XiQIgp4feR4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заметим, что классы: 0 — корабль влево, 1 — корабль вправо, 2 — ничего. Тогда пом матрице видно, что класс \"ничего\" никогда не определяется как лево/право (3я строчка матрицы), право было интерпретировано как ничего 2 раза, лево 1 (3й столбец матрицы.)\n",
        "\n",
        "При этом, ошибочное определение \"право\" как лево было в 20 случаях, наоборот в 50. \n",
        "\n",
        "Делаем вывод, что классы не различаются между собой."
      ],
      "metadata": {
        "id": "1Dln5ycDhqnA"
      },
      "id": "1Dln5ycDhqnA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь я вывожу график классов, уменьшив размерность с помощью T-SNE"
      ],
      "metadata": {
        "id": "_A9qYEMPeRrJ"
      },
      "id": "_A9qYEMPeRrJ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test2, y_pred2) "
      ],
      "metadata": {
        "id": "lw9N516zmGnp"
      },
      "id": "lw9N516zmGnp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "_n6t-mojeQJg"
      },
      "id": "_n6t-mojeQJg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZGr8eakRV8RH"
      },
      "id": "ZGr8eakRV8RH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}